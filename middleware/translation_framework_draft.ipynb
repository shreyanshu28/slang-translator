{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c388e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Please keep in mind that this whole document is only\n",
    "to give a general idea of what to implement. \n",
    "These are not functioning codes.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d30e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce41787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61d564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1acc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17772a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for formality. Does not work on my laptop.\n",
    "es_host = \"http://localhost:9200\"\n",
    "es_user = \"elastic\"\n",
    "es_password = \"1234\"\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=es_host,  # \"http://localhost:9200\"\n",
    "    http_auth=(es_user, es_password)   # credentials for basic authentication\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438e3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft : implementation step\n",
    "######################################\n",
    "# translate regular sentence to slang#\n",
    "######################################\n",
    "\n",
    "input_str = \"I have something to say\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3f9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7b81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_doc = nlp(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d412e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e631bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "something\n"
     ]
    }
   ],
   "source": [
    "for np in str_doc.noun_chunks:\n",
    "    print(np)\n",
    "# print noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ea59a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To find and return subject of a preprocessed sentence.\"\"\"\n",
    "# I wrote the function based on which one may\n",
    "# omit the subject of a sentence with a possibility. \n",
    "# This is not used now, as I still don't\n",
    "# know how to calculate the weight of such omission.\n",
    "def subject_find(doc):\n",
    "    for token in doc:\n",
    "        if \"subj\" in token.dep_:\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            return doc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ed3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do slang dictionary query with part of the input sentence\n",
    "\"\"\"returns all possible k-word-shingle for the input sentence.\n",
    "form: list, [[1-shingle][2-shingle]...[k-shingle]]\"\"\" \n",
    "def multiple_shingle(doc_str):\n",
    "    doc = doc_str.split(\" \")\n",
    "    shingle_lst=[]\n",
    "    for k in range(0,len(doc)):\n",
    "        shingle_lst_temp = []\n",
    "        for i in range(len(doc)-k):\n",
    "            shingle_lst_temp.append(doc[i:k+i+1])\n",
    "        shingle_lst.append(shingle_lst_temp)\n",
    "    return shingle_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da4259fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['I'], ['have'], ['something'], ['to'], ['say']],\n",
       " [['I', 'have'], ['have', 'something'], ['something', 'to'], ['to', 'say']],\n",
       " [['I', 'have', 'something'],\n",
       "  ['have', 'something', 'to'],\n",
       "  ['something', 'to', 'say']],\n",
       " [['I', 'have', 'something', 'to'], ['have', 'something', 'to', 'say']],\n",
       " [['I', 'have', 'something', 'to', 'say']]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_shingle(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"search in slang database based on shingles,\n",
    "return slang and the corresponding shingle.\n",
    "NOTE: not finished. \"\"\"\n",
    "def slang_search(shingle_lst):\n",
    "    lst_search_result = []\n",
    "    for i in range(len(shingle_lst)):\n",
    "        list_temp = shingle_lst[i]\n",
    "        for j in range(len(list_temp)):\n",
    "            search_result = es.search(index=\"slang\",query={\"match\": {\n",
    "                              \"expansion\": list_temp[j]}})\n",
    "            # TODO: make it a fuzzy search\n",
    "            if search_result[\"hits\"][\"hits\"]:\n",
    "                for hit in search_result[\"hits\"][\"hits\"]:\n",
    "                    lst_search_result.append((list_temp[j],hit[\"abbreviation\"]))\n",
    "    return lst_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "214dc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"remove stop words,\n",
    "perform a word association based on twitter corpus.\n",
    "perform ES query based on associated words.\n",
    "return: corresponding word and associated emoji as list of tuple.\n",
    "NOTE: not finished. \"\"\"\n",
    "\n",
    "def emoji_search(input_str):\n",
    "    emoji_search_results = []\n",
    "    en_stops = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_list = [x.strip() for x in input_str.split(\" \")]\n",
    "    model = Word2Vec.load('model.bin')\n",
    "    for word in word_list:\n",
    "        if word not in en_stops:\n",
    "            # perform association\n",
    "            association_list = model.wv.most_similar(word)\n",
    "            # perform emoji search\n",
    "            for word_associated in association_list:\n",
    "            # TODO: search for emoji with keywords related\n",
    "            # store in list_of_emoji\n",
    "            # TODO: return word_associated with associated emoji\n",
    "                emoji_search_results.append(word,list_of_emoji)\n",
    "    return emoji_search_results\n",
    "    # TODO: can also based on api to reversedictionary.com\n",
    "    # which gives associated words to noun phrases: \n",
    "    # 1. extract noun phrases with nlp().noun_chunks,2.search\n",
    "    # the phrase up in reversedictionary.com, and\n",
    "    # 3.perform query with ES in emoji dataset with obtained \n",
    "    # set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The general function that would \n",
    "translate input to sentence with slang&emoji.\n",
    "return&print translated sentence.\n",
    "To be continued.\n",
    "\"\"\"\n",
    "def translation_style(input_str):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
