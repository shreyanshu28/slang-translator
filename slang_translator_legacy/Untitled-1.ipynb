{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch     \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class ShapeChecker():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.shapes = {} # Keep a cache of every axis-name seen\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "        for name, new_dim in parsed.items():\n",
    "            old_dim = self.shapes.get(name, None)\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "            \n",
    "            if old_dim is None:\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "        \n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                         f\"    found: {new_dim}\\n\"\n",
    "                         f\"    expected: {old_dim}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path1, path2, reverse=False):\n",
    "    # input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    # print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    lines1 = np.array(open(path1, encoding='utf-8').\\\n",
    "         read().strip().split('\\n'))\n",
    "    lines2 = np.array(open(path2, encoding='utf-8').\\\n",
    "         read().strip().split('\\n'))\n",
    "\n",
    "    return lines1, lines2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_raw, context_raw = loadData(\"informal.txt\", \"formal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do have it. Please send me a message and I will send it to you.\n",
      "I have it if you would like it... message me and I'll gladly send it to you!!\n"
     ]
    }
   ],
   "source": [
    "print(context_raw[-1])\n",
    "print(target_raw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ConcatDataset.__init__() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[0;32m      4\u001b[0m is_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(size\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(target_raw),)) \u001b[39m<\u001b[39m \u001b[39m0.8\u001b[39m\n\u001b[0;32m      7\u001b[0m train_raw \u001b[39m=\u001b[39m (\n\u001b[1;32m----> 8\u001b[0m     torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mConcatDataset(context_raw[is_train], target_raw[is_train], shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m, num_workers \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m )\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: ConcatDataset.__init__() got an unexpected keyword argument 'shuffle'"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "\n",
    "train_raw = (\n",
    "    torch.utils.data.ConcatDataset(context_raw[is_train], target_raw[is_train]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8bba4f2be892cbd4f39a9f240acc2c7ebb8cef7264d56c87dbb8c6b0bcbe231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
